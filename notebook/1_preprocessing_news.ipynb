{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Khwj2EWTo8Ac"
      },
      "outputs": [],
      "source": [
        "import re, unicodedata\n",
        "\n",
        "EMOJI_SYMBOL_RE = re.compile(\n",
        "    \"[\"                         # BMP(비트맵 이미지 포맷)\n",
        "    \"\\u2190-\\u21FF\"             # arrows\n",
        "    \"\\u2300-\\u23FF\"             # misc technical\n",
        "    \"\\u2460-\\u24FF\"             # enclosed alphanumerics\n",
        "    \"\\u25A0-\\u25FF\"             # geometric shapes (■◆▲○●…)\n",
        "    \"\\u2600-\\u26FF\"             # misc symbols (☀☂☏…)\n",
        "    \"\\u2700-\\u27BF\"             # dingbats (✔✖✈…)\n",
        "    \"\\u2B00-\\u2BFF\"             # misc symbols & arrows\n",
        "    \"\\u3000-\\u303F\"             # CJK symbols (、。・《》【】…)\n",
        "    \"\\uFE0F\"                    # variation selector-16\n",
        "    \"\\u200d\"                    # zero width joiner\n",
        "    \"]\"\n",
        "    \"|\"\n",
        "    \"[\"                         # 보충 평면(astral)\n",
        "    \"\\U0001F000-\\U0001FAFF\"     # emoticons/pictographs/transport/etc.\n",
        "    \"\\U0001FB00-\\U0001FBFF\"\n",
        "    \"]\", flags=re.UNICODE)\n",
        "\n",
        "BRACKET_REMOVE_WORDS = {\n",
        "    \"기고\", \"종합\", \"취재현장\", \"현장\", \"취재\", \"데스크\", \"시선집중\",\n",
        "    \"기자수첩\", \"사설\", \"인사이드\", \"인사이트\", \"쇼\", \"스토리\", \"칼럼\",\n",
        "    \"앵커\",\"자막\",\"자막뉴스\",\"리포트\",\"특보\",\"중계\",\"속보\",\"단독\",\"전문\",\n",
        "    \"사진\",\"자료사진\",\"영상\",\"그래픽\",\"자료\", \"신문\",\"탐사보도\", \"컨설팅\",\n",
        "    \"KBS\",\"MBC\",\"SBS\",\"YTN\",\"JTBC\",\"MBN\",\"TV조선\",\"채널A\", \"프리즘\",\n",
        "    \"연합뉴스\",\"뉴시스\",\"뉴스\", \"주장\", \"파이낸셜뉴스\", \"뉴스투데이\",\n",
        "    \"뉴스25\", \"판결 앤 이슈\", \"뉴스데스크\", \"서울경제\", \"뉴스와 시각\", \"the300\",\n",
        "}\n",
        "BRACKET_REMOVE_RE = re.compile(\n",
        "    r\"(?P<open>[\\[\\(\\uFF3B\\uFF08])\"\n",
        "    r\"(?P<inner>[^()\\[\\]\\uFF3B\\uFF3D\\uFF08\\uFF09]{1,120})\" # 대괄호/일반괄호 내부 텍스트 데이터\n",
        "    r\"(?P<close>[\\]\\)\\uFF3D\\uFF09])\"\n",
        ")\n",
        "\n",
        "# 중요한 대괄호 정보 보존\n",
        "def IMPORTANT_INFO_SAVE(inner: str) -> bool:\n",
        "    inner = inner.strip()\n",
        "    if \"법\" in inner or \"법률\" in inner:\n",
        "        return True\n",
        "    if re.search(r\"제\\d+조\", inner):\n",
        "        return True\n",
        "    if re.search(r\"\\d{4}[-./]\\d{1,2}[-./]\\d{1,2}\", inner): # 날짜 정보\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# 방송사/기자 사인과 제작 크레딧 제거 정규식\n",
        "NEWS_AGENCIES = r\"(?:KBS|MBC|SBS|YTN|JTBC|MBN|TV\\s*조선|채널A|연합뉴스TV)\"\n",
        "CREDIT_ROLE   = r\"(?:촬영기자|VJ|카메라기자|사진기자?|영상(?:편집|취재)?|편집|그래픽|CG|자료|연출|구성|제작|자막)\"\n",
        "\n",
        "# 기자 사인(\"~기자가 취재했습니다.\",\"~뉴스 ~입니다.\")\n",
        "REPORTER_SIGN_RE = re.compile(rf\"\"\"\n",
        "    (?:{NEWS_AGENCIES})\\s*뉴스\\s*[가-힣A-Za-z·]{{2,20}}\\s*입니다[\\.…!\"]*\n",
        "    |\n",
        "    [가-힣A-Za-z·]{{2,20}}\\s*기자(?:가|는)?\\s*\n",
        "        (?:취재|보도|전해드렸|전해드리|리포트)\\w*\n",
        "        [\\.…!\"]*\n",
        "\"\"\", re.VERBOSE)\n",
        "\n",
        "AGENCY_SIGN_RE = re.compile(rf\"\"\"\n",
        "    (?:(?<=^)|(?<=[\\.\\?!]\\s))\n",
        "    (?:{NEWS_AGENCIES})\\s*\n",
        "    [가-힣A-Za-z·]{{2,20}}\\s*\n",
        "    (?:기자)?\\s*입니다\n",
        "    [\\.…!\")]*\n",
        "\"\"\", re.VERBOSE)\n",
        "\n",
        "REPORTER_INLINE_RE = re.compile(\n",
        "    r\"(?<!\\S)[가-힣A-Za-z·]{2,20}\\s+기자\\s*[:=]\\s*\"\n",
        ")\n",
        "\n",
        "# 제작 크레딧 블록(\"촬영기자:~/그래픽:~\")\n",
        "PRODUCT_CREDITS_RE = re.compile(rf\"\"\"\n",
        "    {CREDIT_ROLE}\\s*[:=]\\s*[가-힣A-Za-z·]{{2,20}}\n",
        "    (?:\\s*[/,]\\s*{CREDIT_ROLE}\\s*[:=]\\s*[가-힣A-Za-z·]{{2,20}})*\n",
        "\"\"\", re.VERBOSE)\n",
        "\n",
        "def STRIP_NEWS_CREDITS(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    t = text\n",
        "    t = PRODUCT_CREDITS_RE.sub(' ', t)\n",
        "    t = REPORTER_INLINE_RE.sub(' ', t)\n",
        "    t = REPORTER_SIGN_RE.sub(' ', t)\n",
        "    t = AGENCY_SIGN_RE.sub(' ', t)\n",
        "    return t\n",
        "\n",
        "# 토크나이즈용 구분자(공백, 슬래시, 콜론, 쉼표, 바)\n",
        "_SEP = re.compile(r\"[\\/:\\|\\s,]+\")\n",
        "\n",
        "def rm_inner_tag(inner: str) -> bool:\n",
        "    # 주요 정보 여부 체크\n",
        "    if IMPORTANT_INFO_SAVE(inner):\n",
        "        return False\n",
        "    tokens = [tok for tok in _SEP.split(inner.strip()) if tok]\n",
        "    # inner 토큰 중 금지어 일치 시 제거\n",
        "    if any(tok in BRACKET_REMOVE_WORDS for tok in tokens):\n",
        "        return True\n",
        "    # inner 데이터가 기자/앵커로 끝나는 경우 제거\n",
        "    if any(tok.endswith((\"기자\", \"앵커\")) for tok in tokens):\n",
        "        return True\n",
        "    # inner 토큰 중 금지어 하나라도 포함 시 제거\n",
        "    if any(any(bad in inner for bad in BRACKET_REMOVE_WORDS) for _ in [0]):\n",
        "        return True\n",
        "    # 뉴스 크레딧 형태 제거\n",
        "    if re.search(r\"(?:VJ|{CREDIT_ROLE})\\s*=\\s*(연합뉴스|뉴시스|뉴스1|{NEWS_AGENCIES})\", inner):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# 미리 등록한 삭제 대상 체크 및 제거\n",
        "def STRIP_NOISE_TAGS(text: str) -> str:\n",
        "    def check_inner_tags(m: re.Match) -> str:\n",
        "        inner = m.group('inner').strip()\n",
        "        return \" \" if rm_inner_tag(inner) else m.group(0)\n",
        "    return BRACKET_REMOVE_RE.sub(check_inner_tags, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Lz3WQLZJxE1v"
      },
      "outputs": [],
      "source": [
        "# 한중일 통합 한자 범위\n",
        "HANJA_RE = re.compile(r\"[\\u3400-\\u4DBF\\u4E00-\\u9FFF\\uF900-\\uFAFF\\U00020000-\\U0002EBEF]\")\n",
        "\n",
        "def STRIP_HANJA_PAREN_DUP(text: str) -> str:\n",
        "    def repl(m: re.Match) -> str:\n",
        "        inner = m.group('inner').strip()\n",
        "        # 중요 정보는 그대로 둠\n",
        "        if IMPORTANT_INFO_SAVE(inner):\n",
        "            return m.group(0)\n",
        "\n",
        "        # 한자 비율 계산 -> 괄호 내 절반 이상 한자일 때 제거\n",
        "        core = re.sub(r\"[\\W_]\", \"\", inner)  # 기호/공백 제거\n",
        "        if not core:\n",
        "            return m.group(0)\n",
        "        hanja_cnt = len(HANJA_RE.findall(core))\n",
        "        ratio = hanja_cnt / len(core)\n",
        "\n",
        "        # 괄호 바로 앞 한국어 -> '설명용 한자(데이터 중복)' 제거\n",
        "        left_ctx = text[:m.start()].rstrip()\n",
        "        last_char = left_ctx[-1] if left_ctx else \"\"\n",
        "        left_is_korean = bool(re.search(r\"[가-힣]\", last_char))\n",
        "\n",
        "        if hanja_cnt > 0 and (ratio >= 0.5 or left_is_korean):\n",
        "            return \"\"\n",
        "        return m.group(0)\n",
        "\n",
        "    return BRACKET_REMOVE_RE.sub(repl, text)\n",
        "\n",
        "try:\n",
        "    import hanja as _hanja\n",
        "    def HANJA_TO_HANGUL(text: str) -> str:\n",
        "        # 'substitution': 가능한 한자만 한글로 치환\n",
        "        return _hanja.translate(text, 'substitution')\n",
        "except Exception:\n",
        "    COMMON_HANJA_MAP = {\n",
        "        \"李\":\"이\",\"金\":\"김\",\"朴\":\"박\",\"崔\":\"최\",\"鄭\":\"정\",\"趙\":\"조\",\"姜\":\"강\",\"韓\":\"한\",\"尹\":\"윤\",\n",
        "        \"張\":\"장\",\"申\":\"신\",\"林\":\"임\",\"任\":\"임\",\"文\":\"문\",\"劉\":\"유\",\"柳\":\"유\",\"吳\":\"오\",\"洪\":\"홍\",\n",
        "        \"高\":\"고\",\"權\":\"권\",\"裵\":\"배\",\"朱\":\"주\",\"馬\":\"마\",\"車\":\"차\",\"宋\":\"송\"\n",
        "    }\n",
        "    def HANJA_TO_HANGUL(text: str) -> str:\n",
        "        return \"\".join(COMMON_HANJA_MAP.get(ch, ch) for ch in text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hyUY6gcc0NGi"
      },
      "outputs": [],
      "source": [
        "EMAIL_RE = re.compile(r\"[A-Za-z0-9._%+\\-]+@[A-Za-z0-9.\\-]+\\.[A-Za-z]{2,}\")\n",
        "PHONE_RE   = re.compile(r\"(?:\\+?82[-\\s]?)?0?\\d{1,2}[-\\s]?\\d{3,4}[-\\s]?\\d{4}\")\n",
        "\n",
        "# 카테고리 제거 정규식\n",
        "CATEGORY_REMOVE = r\"(?:제보하기|제보|연락처|문의|전화|이메일|메일|카카오톡|카톡|라인|사이트)\"\n",
        "\n",
        "# [카테고리]: 연락처\n",
        "LABELED_CONTACT_RE = re.compile(\n",
        "    r\"({CATEGORY_REMOVE})\\s*[:=]\\s*[^.\\n]*\"\n",
        ")\n",
        "\n",
        "# [카테고리] 연락처(:x)\n",
        "BRACKETED_LABEL_RE = re.compile(\n",
        "    r\"[\\[\\(]\\s*({CATEGORY_REMOVE})\\s*[\\]\\)]\"\n",
        ")\n",
        "\n",
        "# SNS/플랫폼 구독/채널추가 CTA\n",
        "CTA_RE = re.compile(\n",
        "    r\"(?:네이버|유튜브|YouTube|인스타그램|페이스북|트위터|X|카카오톡|카톡|라인|텔레그램|밴드|틱톡|카카오스토리)\"\n",
        "    r\"\\s*[^.\\n]*?(?:구독|팔로우|친구\\s*추가|채널\\s*추가|구독해|검색해\\s*채널\\s*추가)[^.\\n]*\",\n",
        "    re.IGNORECASE\n",
        ")\n",
        "\n",
        "# 제보 캠페인 문구\n",
        "JEBO_TAGLINE_RE = re.compile(\n",
        "    r\"[※\\s`'\\\"“”‘’]*당신의\\s*제보가\\s*뉴스가\\s*됩니다[^\\n]*\"\n",
        ")\n",
        "\n",
        "# 기사 말미에 붙는 '기사문의, 제보하기 …' -> 문서 끝까지 제거\n",
        "TRAILING_FROM_JEBO = re.compile(r\"(?:제보하기|독자문의|기사문의|제보\\s*문의)[\\s\\S]*$\", re.UNICODE)\n",
        "\n",
        "def STRIP_CONTACT_INFO(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    t = text\n",
        "    t = LABELED_CONTACT_RE.sub(' ', t)\n",
        "    t = BRACKETED_LABEL_RE.sub(' ', t)\n",
        "    t = EMAIL_RE.sub(' ', t)\n",
        "    t = PHONE_RE.sub(' ', t)\n",
        "    t = CTA_RE.sub(' ', t)\n",
        "\n",
        "    t = JEBO_TAGLINE_RE.sub(' ', t)\n",
        "    t = TRAILING_FROM_JEBO.sub(' ', t)\n",
        "    return t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vKl38mRPC7Jw"
      },
      "outputs": [],
      "source": [
        "def _tidy_punct(text: str) -> str:\n",
        "    t = re.sub(r\"\\s*/\\s*(?=[\\s\\W]|$)\", \" \", text)   # 불필요 슬래시 제거\n",
        "    t = re.sub(r\"\\s*([,;:])\\s*(?=[\\.\\?!])\", \"\", t)\n",
        "    t = re.sub(r\"\\s+([,;:])\", r\" \\1\", t)\n",
        "    t = re.sub(r\"([(\\[])\\s+\", r\"\\1\", t)\n",
        "    t = re.sub(r\"\\s+([)\\]])\", r\"\\1\", t)\n",
        "    t = re.sub(r\"\\s{2,}\", \" \", t)\n",
        "    return t.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eg3rijFLxHU9"
      },
      "outputs": [],
      "source": [
        "PUNCT_TRANSLATE = str.maketrans({\n",
        "    \"…\": \"...\", \"·\": \" \", \"•\": \" \", \"―\": \"-\", \"–\": \"-\", \"—\": \"-\",\n",
        "    \"“\": \"\\\"\", \"”\": \"\\\"\", \"‘\": \"'\", \"’\": \"'\",\n",
        "    \"◆\":\" \", \"■\":\" \", \"▲\":\" \", \"△\":\" \", \"▶\":\" \", \"▷\":\" \", \"▼\":\" \", \"▽\":\" \", \"※\":\" \"\n",
        "})\n",
        "\n",
        "def normalize_korean(text:str) -> str:\n",
        "    if not isinstance(text, str): return ''\n",
        "    t = unicodedata.normalize('NFC', text) # 한국어 일관된 형태(초성/중성 분해)\n",
        "    t = t.translate(PUNCT_TRANSLATE)\n",
        "\n",
        "    t = STRIP_NOISE_TAGS(t)\n",
        "    t = STRIP_NEWS_CREDITS(t)\n",
        "    t = STRIP_HANJA_PAREN_DUP(t)\n",
        "    t = HANJA_TO_HANGUL(t)\n",
        "    t = STRIP_CONTACT_INFO(t)\n",
        "\n",
        "    t = EMOJI_SYMBOL_RE.sub(' ', t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "\n",
        "    t = _tidy_punct(t)\n",
        "    return t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Pv571mcYqgL3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def preprocess_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    out['title_norm'] = out['title'].apply(normalize_korean)\n",
        "    out['content_norm'] = out['content'].apply(normalize_korean)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MKc4541br-cr"
      },
      "outputs": [],
      "source": [
        "def load_preprocess_data(path: str, sheet_name=0) -> pd.DataFrame:\n",
        "    usecols = ['category', 'date', 'projectId', 'title', 'content', 'url']\n",
        "    df = pd.read_excel(\n",
        "        path,\n",
        "        sheet_name=sheet_name,\n",
        "        engine=\"openpyxl\",\n",
        "        dtype=str,\n",
        "        usecols=usecols\n",
        "    )\n",
        "\n",
        "    out = preprocess_df(df)\n",
        "    return out\n",
        "\n",
        "out = load_preprocess_data(\"1. (NEWS)_(개인정보보호법__정보통신망법).xlsx\", sheet_name=\"news\")\n",
        "out.to_excel(\"preprocess_news_part_1.xlsx\", index=False)\n",
        "out = load_preprocess_data(\"2. (NEWS)_(자본시장법__특정금융정보법__전자금융거래법__전자증권법__금융소비자보호법).xlsx\", sheet_name=\"news\")\n",
        "out.to_excel(\"preprocess_news_part_2.xlsx\", index=False)\n",
        "out = load_preprocess_data(\"3. (NEWS)_(아동복지법).xlsx\", sheet_name=\"news\")\n",
        "out.to_excel(\"preprocess_news_part_3.xlsx\", index=False)\n",
        "out = load_preprocess_data(\"4. (NEWS)_(중대재해처벌법).xlsx\", sheet_name=\"news\")\n",
        "out.to_excel(\"preprocess_news_part_4.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "뉴스 데이터 추가 전처리 - 기사 좋아요 및 댓글 수 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "####################################\n",
        "# 해당 코드는 로컬 터미널 환경에서 작성 및 실행되었으며, jupyter 환경에서는 호환이 불가함을 확인했습니다.\n",
        "# 해당 코드의 전처리 결과 파일은 data 폴더에 저장하였습니다.\n",
        "####################################\n",
        "\n",
        "import asyncio\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Optional, Dict, Any\n",
        "\n",
        "import pandas as pd\n",
        "from playwright.async_api import async_playwright\n",
        "from tqdm import tqdm   # 진행바\n",
        "\n",
        "# ===== 사용자 설정 =====\n",
        "INPUT_PATH   = r\"preprocess_news_part_1.xlsx\"\n",
        "OUTPUT_PATH  = None\n",
        "URL_COL      = \"url\"\n",
        "HEADLESS     = True\n",
        "NAV_WAIT     = \"networkidle\"\n",
        "PAGE_TIMEOUT = 25_000\n",
        "SCROLL_WAIT  = 250\n",
        "# ======================\n",
        "\n",
        "def to_int(s: Optional[str]) -> Optional[int]:\n",
        "    if not s:\n",
        "        return None\n",
        "    digits = re.sub(r\"[^\\d]\", \"\", str(s))\n",
        "    return int(digits) if digits.isdigit() else None\n",
        "\n",
        "def load_table(path: str) -> pd.DataFrame:\n",
        "    p = Path(path)\n",
        "    if p.suffix.lower() in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(p)\n",
        "    return pd.read_csv(p)\n",
        "\n",
        "def save_table(df: pd.DataFrame, in_path: str, out_path: Optional[str]) -> str:\n",
        "    in_p = Path(in_path)\n",
        "    out_p = Path(out_path) if out_path else in_p.with_name(in_p.stem + \"_with_metrics\" + in_p.suffix)\n",
        "    if out_p.suffix.lower() in [\".xlsx\", \".xls\"]:\n",
        "        df.to_excel(out_p, index=False)\n",
        "    else:\n",
        "        df.to_csv(out_p, index=False, encoding=\"utf-8-sig\")\n",
        "    return str(out_p)\n",
        "\n",
        "async def get_comment_count(page) -> Optional[int]:\n",
        "    selectors = [\n",
        "        \"a.u_cbox_btn_view > span.u_cbox_count\",\n",
        "        \"span.u_cbox_count\",\n",
        "        \"#comment_count\",\n",
        "        \"a#comment_count > em\",\n",
        "        \"span#comment_count\",\n",
        "    ]\n",
        "    for sel in selectors:\n",
        "        try:\n",
        "            el = await page.query_selector(sel)\n",
        "            if el:\n",
        "                txt = (await el.text_content() or \"\").strip()\n",
        "                n = to_int(txt)\n",
        "                if n is not None:\n",
        "                    return n\n",
        "        except Exception:\n",
        "            pass\n",
        "    try:\n",
        "        html = await page.content()\n",
        "        m = re.search(r\"(댓글)\\D*?([\\d,]{1,9})\", html)\n",
        "        if m:\n",
        "            return to_int(m.group(2))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "async def get_like_count(page) -> Optional[int]:\n",
        "    try:\n",
        "        spans = await page.query_selector_all(\"span.u_likeit_text._count.num\")\n",
        "        vals = []\n",
        "        for sp in spans:\n",
        "            txt = (await sp.text_content() or \"\").strip()\n",
        "            n = to_int(txt)\n",
        "            if n is not None:\n",
        "                vals.append(n)\n",
        "        if vals:\n",
        "            return min(vals)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        el = await page.query_selector(\n",
        "            'div.u_likeit_module a.u_likeit_list_btn._button[data-type=\"like\"] span.u_likeit_list_count._count'\n",
        "        )\n",
        "        if el:\n",
        "            txt = (await el.text_content() or \"\").strip()\n",
        "            return to_int(txt)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        html = await page.content()\n",
        "        m = re.search(r\"추천\\D*?([\\d,]{1,9})\", html)\n",
        "        if m:\n",
        "            return to_int(m.group(1))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "async def scrape_one(page, url: str) -> Dict[str, Any]:\n",
        "    r = {\"comment_count\": None, \"like_count\": None}\n",
        "    if not isinstance(url, str) or not url.startswith(\"http\"):\n",
        "        return r\n",
        "    try:\n",
        "        await page.goto(url, wait_until=NAV_WAIT, timeout=PAGE_TIMEOUT)\n",
        "        await page.wait_for_timeout(SCROLL_WAIT)\n",
        "        await page.mouse.wheel(0, 800)\n",
        "        await page.wait_for_timeout(SCROLL_WAIT)\n",
        "\n",
        "        r[\"comment_count\"] = await get_comment_count(page)\n",
        "        r[\"like_count\"]    = await get_like_count(page)\n",
        "\n",
        "        if r[\"like_count\"] is None:\n",
        "            await page.evaluate(\"window.scrollTo(0, 0)\")\n",
        "            await page.wait_for_timeout(SCROLL_WAIT)\n",
        "            r[\"like_count\"] = await get_like_count(page)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return r\n",
        "\n",
        "async def main():\n",
        "    df = load_table(INPUT_PATH)\n",
        "    if URL_COL not in df.columns:\n",
        "        raise ValueError(f\"'{URL_COL}' 컬럼이 입력 파일에 없습니다. 현재 컬럼: {list(df.columns)}\")\n",
        "\n",
        "    for col in [\"comment_count\", \"like_count\"]:\n",
        "        if col not in df.columns:\n",
        "            df[col] = None\n",
        "\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=HEADLESS)\n",
        "        ctx = await browser.new_context(\n",
        "            user_agent=(\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                        \"Chrome/120.0.0.0 Safari/537.36\"),\n",
        "            locale=\"ko-KR\",\n",
        "        )\n",
        "        page = await ctx.new_page()\n",
        "\n",
        "        # tqdm으로 진행바 표시\n",
        "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing articles\"):\n",
        "            url = str(row[URL_COL]) if pd.notna(row[URL_COL]) else \"\"\n",
        "            metrics = await scrape_one(page, url)\n",
        "            df.at[idx, \"comment_count\"] = metrics[\"comment_count\"]\n",
        "            df.at[idx, \"like_count\"]    = metrics[\"like_count\"]\n",
        "\n",
        "        await browser.close()\n",
        "\n",
        "    out = save_table(df, INPUT_PATH, OUTPUT_PATH)\n",
        "    print(f\"[done] saved -> {out}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "law-issue2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
